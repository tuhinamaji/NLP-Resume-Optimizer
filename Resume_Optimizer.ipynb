{"cells":[{"cell_type":"code","execution_count":null,"id":"a48b3056","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a48b3056","executionInfo":{"status":"ok","timestamp":1701649128681,"user_tz":480,"elapsed":74112,"user":{"displayName":"Jane Wang","userId":"09372471752354653558"}},"outputId":"427d8a7e-70e2-418c-a6b5-d836d48c8002"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m221.4/221.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","llmx 0.0.15a0 requires cohere, which is not installed.\n","llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m177.8/177.8 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m502.4/502.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m105.3/105.3 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m699.4/699.4 kB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.6/72.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires kaleido, which is not installed.\n","lida 0.0.10 requires python-multipart, which is not installed.\n","tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["# Install Packages (requirements.txt)\n","!pip install streamlit -q\n","!pip install openai -q\n","!pip install PyPDF2 -q\n","!pip install langchain -q\n","!pip install chromadb -q\n","!pip install tiktoken -q\n"]},{"cell_type":"code","execution_count":null,"id":"464e02da","metadata":{"id":"464e02da"},"outputs":[],"source":["%%writefile resume_app.py\n","\n","# Resume App\n","\n","# Imports\n","import streamlit as st\n","import openai\n","from openai import OpenAI\n","import PyPDF2\n","from langchain.vectorstores import Chroma\n","from langchain.embeddings import OpenAIEmbeddings\n","from langchain.document_loaders.telegram import text_to_docs\n","from langchain.chains import RetrievalQA\n","from langchain.prompts import PromptTemplate\n","from langchain. chat_models import ChatOpenAI\n","\n","\n","# Set API Key\n","with st.sidebar:\n","    openai_api_key = st.text_input(\"OpenAI API Key\",\n","                                   key=\"file_qa_api_key\",\n","                                   type=\"password\",\n","                                  )\n","\n","# Set the LLM Model\n","model=\"gpt-4-1106-preview\"\n","\n","# Define Text Extraction Function\n","def file_text(file):\n","    # Resume Text Extraction\n","    reader = PyPDF2.PdfReader(file)\n","\n","    # Iterate over each page and extract text\n","    file_text = \"\"\n","    for page_num in range(len(reader.pages)):\n","        file_text += reader.pages[page_num].extract_text()\n","\n","    return file_text\n","\n","# Define cleaned text functon\n","def clean_text(text):\n","    # Implement your cleaning logic here\n","    cleaned_text = text.lower() # Example: simple lowercasing\n","    return cleaned_text\n","\n","# Define ChromaDB Function\n","#@st.cache_resource\n","def reading_resume(resume_text):\n","    # Set the Request for Facts\n","    request = \"\"\"\n","    Using the following resume text, please return a list of all facts and inferred facts about the user\n","    formatted as 'a+b+c+...' with each entry stated as an individual sentence stating a fact.\n","    Collect as many facts as you can from the resume including details about time periods spent at each company.\n","    For experience facts, include context such as which position each experience fact is related to\n","    and the relevant time when it was applicable, based on the position.\n","\n","    In examining responsibilities, go beyond the surface-level descriptions.\n","    Uncover the intricacies and specific details of their duties.\n","\n","    Craft the responses with an in-depth understanding, considering hidden skills and unique contributions.\n","    Break down and really understand each aspect of their duties to endorse the candidate.\n","    Keep the Technical skills or skills section as is. Do not  paraphrase it,\n","    keep it as comma separated lit of skills.\n","    For each experience in each section (e.g., Education, Work Experience, Skills),\n","    do not group experience in one section together, list the facts in a clear manner.\n","\n","    Give more insights into the industry, soft skills and initiative the candidate showed. really market them back.\n","\n","    Whenever relevant, for each fact include the section (EXPERIENCE, SKILLS) that the fact was found under in the format 'SECTION: fact'\n","\n","    Collect no less than 200 fact statements.\n","\n","    Do not include any other text or characters.\n","\n","    \"\"\"\n","\n","    # Set the OpenAI client\n","    client = OpenAI(api_key = openai_api_key)\n","\n","    # Set Embeddings Model\n","    embeddings = OpenAIEmbeddings(api_key = openai_api_key)\n","\n","    # Collect Messages\n","    messages = [\n","        {\n","            \"role\": \"user\",\n","            \"content\": request + resume_text\n","        }\n","    ]\n","    response = client.chat.completions.create(\n","        model=model,\n","        messages=messages,\n","    )\n","\n","    fact_list = response.choices[0].message.content\n","\n","    # Remove the brackets and split the string into a list\n","    facts = fact_list.split(\"+\")\n","\n","    # Clean the facts\n","    data = [clean_text(item) for item in facts]\n","\n","    # Convert to Documents\n","    documents = text_to_docs(data)\n","\n","    # Store embeddings in Chroma\n","    store = Chroma.from_documents(documents,\n","                                  embeddings,\n","                                  ids=[f\"{index}\" for index, _ in enumerate(documents)],\n","                                  collection_name=\"Resume-Embeddings\",\n","                                  #persist_directory='db'\n","                                 )\n","    #store.persist()\n","    return store\n","\n","#Define the Template Function\n","@st.cache_resource\n","def resume_build():\n","\n","    template2 = \"\"\"\n","    You are a bot that generates resumes for users based on your knowledge about the user,\n","\n","    If the text given as the job description does not appear to be an actual job description,\n","    return an error and do not proceed.\n","\n","    First determine if the user is qualified for the position in the job description by comparing known information\n","    about the user to the requirements in the job description. If the user is very clearly unqualified,\n","    return the reason they are unqualified and do not generate a resume.\n","\n","    Based on the known information about the user and the provided job description,\n","    please generate a resume by doing the following:\n","\n","    1. Create a resume using the relevant information known about the user, optimized for the job description.\n","        -Generate only the following sections on the resume: Education, Technical Skills, Work Experience, Academic Projects, Additional Information\n","\n","    2. Edit the entries under skills, without making new skills, to better fit those listed in the job description.\n","\n","    3. For work experience and academic projects sections, edit each bullet point to showcase my contribution, include statistics and quantitative aspects if available.\n","        - Write each bullet point in STAR format with impactful words. Pull important keywords from job description and incorporate them in.\n","\n","    Do not return any of the contents of the job description itself.\n","\n","    Do not make up any information not already known about the user.\n","\n","    KNOWN INFORMATION ABOUT THE USER:\n","    {context}\n","\n","    JOB DESCRIPTION:\n","    {question}\n","    \"\"\"\n","\n","    PROMPT = PromptTemplate(\n","        template = template2, input_variables=[\"context\", \"question\"]\n","    )\n","\n","    # Define the LLM\n","    llm = ChatOpenAI(temperature=0.3, model=model, api_key=openai_api_key)\n","\n","    # Create the Resume Builder\n","    resume_builder = RetrievalQA.from_chain_type(\n","        llm=llm,\n","        chain_type=\"stuff\",\n","        retriever=store.as_retriever(\n","            #search_type=\"mmr\",  # Also test \"similarity\"\n","            search_kwargs={\"k\": 200,\"score_threshold\" : 0.0},\n","        ),\n","        chain_type_kwargs={\"prompt\": PROMPT, },\n","    return_source_documents=True,\n","    )\n","\n","    return resume_builder\n","\n","# GENERATE PAGE VIEW\n","st.title(\"ğŸ“ SCU MSIS Resume Optimizer\")\n","st.write(\"\"\"\n","            Embark on your career journey: Upload your resume to guide the assistant in your professional saga.\n","            Then, present a Job Description for a custom-crafted qualification analysis and resume.\n","            Feeling adventurous? Add more resumes to refine the narrative, with each one teaching me more about your story.\n","            Remember, you're the final editor â€“ review and tweak the results before sending them off into the job application frontier!\n","        \"\"\")\n","uploaded_file = st.file_uploader(\"Upload your resume (PDF).\",\n","                                 type=(\"pdf\")\n","                                )\n","jd_text = st.text_area(\n","    \"Job Description:\",\n","    placeholder=\"Paste Job Description Text Here\",\n",")\n","\n","if st.button('Generate', disabled = (not uploaded_file and not jd_text)):\n","    # Check for Missing Resume\n","    if not uploaded_file:\n","        # Notify of missing Resume\n","        st.write(\"Ready for the next step? Upload your resume and let's roll!\")\n","\n","    # Check for Missing API Key\n","    if uploaded_file and not openai_api_key:\n","        st.info(\"Almost there! Just add your OpenAI API key in the sidebar to keep the adventure going!\")\n","\n","    # Check for Errors and Missing Data\n","    if uploaded_file and not jd_text and openai_api_key:\n","        # Get text from file\n","        resume_text = file_text(uploaded_file)\n","\n","        # Load embeddings into store\n","        store = reading_resume(resume_text)\n","\n","        # Notify of missing JD\n","        st.write(\"Set the stage for me: Enter a Job Description to get the gears turning.\")\n","\n","    # Execute if no errors found\n","    if uploaded_file and jd_text and openai_api_key:\n","        #Set Placeholder Location\n","        placeholder = st.empty()\n","\n","        # Get text from file\n","        resume_text = file_text(uploaded_file)\n","\n","        # Load embeddings into store\n","        placeholder.text(\"Unfolding the chapters of your professional journey from your resume... \")\n","        store = reading_resume(resume_text)\n","\n","        # Create Resume Builder\n","        placeholder.text(\"Crafting your new resume... watch the magic happen!\")\n","        resume_builder = resume_build()\n","\n","        # Generate Resume\n","        result = resume_builder(jd_text)\n","        resume_new = result['result']\n","\n","        #Write Response\n","        placeholder.empty()\n","        st.write(resume_new)"]},{"cell_type":"code","source":["%%writefile resume_app.py\n","\n","# Resume App\n","\n","# Imports\n","import streamlit as st\n","import openai\n","from openai import OpenAI\n","import PyPDF2\n","from langchain.vectorstores import Chroma\n","from langchain.embeddings import OpenAIEmbeddings\n","from langchain.document_loaders.telegram import text_to_docs\n","from langchain.chains import RetrievalQA\n","from langchain.prompts import PromptTemplate\n","from langchain. chat_models import ChatOpenAI\n","\n","\n","# Set API Key\n","with st.sidebar:\n","    openai_api_key = st.text_input(\"OpenAI API Key\",\n","                                   key=\"file_qa_api_key\",\n","                                   type=\"password\",\n","                                   value = \"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\"\n","                                  )\n","\n","# Set the LLM Model\n","#model=\"gpt-3.5-turbo-0613\"\n","model=\"gpt-4-1106-preview\"\n","#model=\"ft:gpt-3.5-turbo-0613:personal::8Nvo6C0W\"\n","\n","# Define Text Extraction Function\n","def file_text(file):\n","    # Resume Text Extraction\n","    reader = PyPDF2.PdfReader(file)\n","\n","    # Iterate over each page and extract text\n","    file_text = \"\"\n","    for page_num in range(len(reader.pages)):\n","        file_text += reader.pages[page_num].extract_text()\n","\n","    return file_text\n","\n","# Define cleaned text functon\n","def clean_text(text):\n","    # Implement your cleaning logic here\n","    cleaned_text = text.lower() # Example: simple lowercasing\n","    return cleaned_text\n","\n","# Define ChromaDB Function\n","#@st.cache_resource\n","def reading_resume(resume_text):\n","    # Set the Request for Facts\n","    request = \"\"\"\n","    Using the following resume text, please return a list of all facts and inferred facts about the user\n","    formatted as 'a+b+c+...' with each entry stated as an individual sentence stating a fact.\n","    Collect as many facts as you can from the resume including details about time periods spent at each company.\n","    For experience facts, include context such as which position each experience fact is related to\n","    and the relevant time when it was applicable, based on the position.\n","\n","    In examining responsibilities, go beyond the surface-level descriptions.\n","    Uncover the intricacies and specific details of their duties.\n","\n","    Craft the responses with an in-depth understanding, considering hidden skills and unique contributions.\n","    Break down and really understand each aspect of their duties to endorse the candidate.\n","    Keep the Technical skills or skills section as is. Do not  paraphrase it,\n","    keep it as comma separated lit of skills.\n","    For each experience in each section (e.g., Education, Work Experience, Skills),\n","    do not group experience in one section together, list the facts in a clear manner.\n","\n","    Give more insights into the industry, soft skills and initiative the candidate showed. really market them back.\n","\n","    Whenever relevant, for each fact include the section (EXPERIENCE, SKILLS) that the fact was found under in the format 'SECTION: fact'\n","\n","    Collect no less than 200 fact statements.\n","\n","    Do not include any other text or characters.\n","\n","    \"\"\"\n","\n","    # Set the OpenAI client\n","    client = OpenAI(api_key = openai_api_key)\n","\n","    # Set Embeddings Model\n","    embeddings = OpenAIEmbeddings(api_key = openai_api_key)\n","\n","    # Collect Messages\n","    messages = [\n","        {\n","            \"role\": \"user\",\n","            \"content\": request + resume_text\n","        }\n","    ]\n","    response = client.chat.completions.create(\n","        model=model,\n","        messages=messages,\n","    )\n","\n","    fact_list = response.choices[0].message.content\n","\n","    # Remove the brackets and split the string into a list\n","    facts = fact_list.split(\"+\")\n","\n","    # Clean the facts\n","    data = [clean_text(item) for item in facts]\n","\n","    # Convert to Documents\n","    documents = text_to_docs(data)\n","\n","    # Store embeddings in Chroma\n","    store = Chroma.from_documents(documents,\n","                                  embeddings,\n","                                  ids=[f\"{index}\" for index, _ in enumerate(documents)],\n","                                  collection_name=\"Resume-Embeddings\",\n","                                  #persist_directory='db'\n","                                 )\n","    #store.persist()\n","    return store\n","\n","#Define the Template Function\n","@st.cache_resource\n","def resume_build():\n","\n","    template2 = \"\"\"\n","    You are a bot that generates resumes for users based on your knowledge about the user,\n","    You are a bot that generates resumes for users based on your knowledge about the user,\n","\n","    If the text given as the job description does not appear to be an actual job description,\n","    return an error and do not proceed.\n","\n","    First determine if the user is qualified for the position in the job description by comparing known information\n","    about the user to the requirements in the job description. If the user is very clearly unqualified,\n","    return the reason they are unqualified and do not generate a resume.\n","\n","    Based on the known information about the user and the provided job description,\n","    please generate a resume by doing the following:\n","\n","    1. Create a resume using the relevant information known about the user, optimized for the job description.\n","        -Generate only the following sections on the resume: Education, Technical Skills, Work Experience, Academic Projects, Additional Information\n","\n","    2. Edit the entries under skills, without making new skills, to better fit those listed in the job description.\n","\n","    3. For work experience and academic projects sections, edit each bullet point to showcase my contribution, include statistics and quantitative aspects if available.\n","        - Write each bullet point in STAR format with impactful words. Pull important keywords from job description and incorporate them in.\n","\n","    Do not return any of the contents of the job description itself.\n","\n","    Do not make up any information not already known about the user.\n","\n","    KNOWN INFORMATION ABOUT THE USER:\n","    {context}\n","\n","    JOB DESCRIPTION:\n","    {question}\n","    \"\"\"\n","\n","    PROMPT = PromptTemplate(\n","        template = template2, input_variables=[\"context\", \"question\"]\n","    )\n","\n","    # Define the LLM\n","    llm = ChatOpenAI(temperature=0.3, model=model, api_key=openai_api_key)\n","    #llm = ChatOpenAI(temperature=0.0, model=\"ft:gpt-3.5-turbo-0613:personal::8Nvo6C0W\", api_key=openai_api_key)\n","\n","    # Create the Resume Builder\n","    resume_builder = RetrievalQA.from_chain_type(\n","        llm=llm,\n","        chain_type=\"stuff\",\n","        retriever=store.as_retriever(\n","            #search_type=\"mmr\",  # Also test \"similarity\"\n","            search_kwargs={\"k\": 200,\"score_threshold\" : 0.0},\n","        ),\n","        chain_type_kwargs={\"prompt\": PROMPT, },\n","    return_source_documents=True,\n","    )\n","\n","    return resume_builder\n","\n","# GENERATE PAGE VIEW\n","st.title(\"ğŸ“ SCU MSIS Resume Optimizer\")\n","st.write(\"\"\"\n","            Embark on your career journey: Upload your resume to guide the assistant in your professional saga.\n","            Then, present a Job Description for a custom-crafted qualification analysis and resume.\n","            Feeling adventurous? Add more resumes to refine the narrative, with each one teaching me more about your story.\n","            Remember, you're the final editor â€“ review and tweak the results before sending them off into the job application frontier!\n","        \"\"\")\n","uploaded_file = st.file_uploader(\"Upload your resume (PDF).\",\n","                                 type=(\"pdf\")\n","                                )\n","jd_text = st.text_area(\n","    \"Job Description:\",\n","    placeholder=\"Paste Job Description Text Here\",\n",")\n","\n","if st.button('Generate', disabled = (not uploaded_file and not jd_text)):\n","    # Check for Missing Resume\n","    if not uploaded_file:\n","        # Notify of missing Resume\n","        st.write(\"Ready for the next step? Upload your resume and let's roll!\")\n","\n","    # Check for Missing API Key\n","    if uploaded_file and not openai_api_key:\n","        st.info(\"Almost there! Just add your OpenAI API key in the sidebar to keep the adventure going!\")\n","\n","    # Check for Errors and Missing Data\n","    if uploaded_file and not jd_text and openai_api_key:\n","        # Get text from file\n","        resume_text = file_text(uploaded_file)\n","\n","        # Load embeddings into store\n","        store = reading_resume(resume_text)\n","\n","        # Notify of missing JD\n","        st.write(\"Set the stage for me: Enter a Job Description to get the gears turning.\")\n","\n","    # Execute if no errors found\n","    if uploaded_file and jd_text and openai_api_key:\n","        #Set Placeholder Location\n","        placeholder = st.empty()\n","\n","        # Get text from file\n","        resume_text = file_text(uploaded_file)\n","\n","        # Load embeddings into store\n","        placeholder.text(\"Unfolding the chapters of your professional journey from your resume... \")\n","        store = reading_resume(resume_text)\n","\n","        # Create Resume Builder\n","        placeholder.text(\"Crafting your new resume... watch the magic happen!\")\n","        resume_builder = resume_build()\n","\n","        # Generate Resume\n","        result = resume_builder(jd_text)\n","        resume_new = result['result']\n","\n","        #Write Response\n","        placeholder.empty()\n","        st.write(resume_new)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y0_Kt8qXLz9Q","executionInfo":{"status":"ok","timestamp":1701649128977,"user_tz":480,"elapsed":303,"user":{"displayName":"Jane Wang","userId":"09372471752354653558"}},"outputId":"269bc239-b5a0-4a70-c773-84b96dc625f1"},"id":"Y0_Kt8qXLz9Q","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing resume_app.py\n"]}]},{"cell_type":"code","execution_count":null,"id":"adb213ab","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"adb213ab","outputId":"229dae60-86b1-4684-e1db-e724444d2349"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n","\u001b[0m\n","\u001b[0m\n","\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n","\u001b[0m\n","\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n","\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.106.218.249:8501\u001b[0m\n","\u001b[0m\n"]}],"source":["!streamlit run resume_app.py\n","# Please note that the first time you run streamlit run it will need to be in the terminal so that you can go through the setup prompts"]},{"cell_type":"code","execution_count":null,"id":"7b6958ff","metadata":{"id":"7b6958ff"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}